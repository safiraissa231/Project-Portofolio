# -*- coding: utf-8 -*-
"""Assessment 1-Prompt Engineering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NmWZccseqM3yX_ulZRB7kxnmI2AjMYCI
"""

import json
import re
import requests
import streamlit as st



# Streamlit app title
st.title("Bahasalab LLM Demo")

# System prompts based on the context or model
prompts = {
    "Mistral": "Summarize the key points discussed in the previous conversation in a brief paragraph in Bahasa Indonesia, not to exceed 300 words.",
    "Llama": "Provide a brief summary in Bahasa Indonesia of the preceding discussion, enclosed within triple backticks, with a maximum length of 300 words.",
    "Qwen": "Craft a succinct summary in Bahasa Indonesia of the conversation initiated by the user, limited to 300 words."
}

# Function to reset session state, except for the API key
def reset_state():
    for key in list(st.session_state.keys()):
        if key != 'api_key':
            del st.session_state[key]

# Sidebar configuration for new chat and model selection
with st.sidebar:
    if st.button('New Chat'):
        reset_state()
    selected_model = st.selectbox("Select Model", ['Mistral', 'Llama', 'Qwen'])

# Input field for API key
if 'api_key' not in st.session_state:
    api_key = st.sidebar.text_input('Enter API key:', type='password')
    if api_key:
        st.session_state['api_key'] = api_key
        st.sidebar.success('API key provided!', icon='âœ…')

# Unified function to generate completions from different models
def generate_completion(prompt, model, messages=None, temperature=0.7, max_tokens=1024, n=1, stop=None):
    endpoint = 'https://api.together.xyz/v1/completions'
    headers = {"Authorization": f"Bearer {st.session_state['api_key']}"}
    json_payload = {
        "model": model,
        "prompt": prompt,
        "messages": messages,
        'temperature': temperature,
        'max_tokens': max_tokens,
        'n': n,
        'stop': stop
    }
    response = requests.post(endpoint, json=json_payload, headers=headers)
    return response.json()

# Main interaction area
if 'api_key' in st.session_state:
    user_prompt = st.text_area("Enter your discussion:")
    if user_prompt and selected_model:
        # Clean and prepare the user prompt
        cleaned_prompt = re.sub(r"\s+", " ", user_prompt.strip())
        system_prompt = prompts.get(selected_model, "")
        complete_prompt = f"{system_prompt}\n\n{cleaned_prompt}" if system_prompt else cleaned_prompt

        # Generate summary based on selected model
        model_name = f"model_name_for_{selected_model}" # Placeholder for actual model name mapping
        response = generate_completion(complete_prompt, model_name, temperature=0.7, max_tokens=1024, n=1)

        # Display the generated summary
        summary = response.get("choices", [{}])[0].get("text", "No summary generated.")
        st.write(summary)