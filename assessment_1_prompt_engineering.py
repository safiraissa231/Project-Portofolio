# -*- coding: utf-8 -*-
"""Assessment 1-Prompt Engineering.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1NmWZccseqM3yX_ulZRB7kxnmI2AjMYCI
"""

import json
import re
import requests
import streamlit as st

# Define prompts for each model in Bahasa Indonesia.
prompts = {
    "Mistral": "Ringkaslah diskusi ini dalam satu paragraf formal yang terdiri dari kalimat tidak langsung, dalam Bahasa Indonesia, dengan batasan maksimal 300 kata.",
    "Llama": "Ringkaslah diskusi ini dalam satu paragraf formal yang terdiri dari kalimat tidak langsung, dalam Bahasa Indonesia, dengan batasan maksimal 300 kata.",
    "Qwen": "Ringkaslah diskusi ini dalam satu paragraf formal yang terdiri dari kalimat tidak langsung, dalam Bahasa Indonesia, dengan batasan maksimal 300 kata."
}

# App title
st.title("Open Source LLMs Model Demo")

# Function to reset state except for the API key.
def reset_state():
    for key in list(st.session_state.keys()):
        if key != 'api_key':
            del st.session_state[key]

# Sidebar for resetting chat and selecting the model.
with st.sidebar:
    if st.button('User Chat'):
        reset_state()
    selected_model = st.selectbox("Select Model", ['Mistral', 'Llama', 'Qwen'])

# Input for the API key.
if 'api_key' not in st.session_state:
    api_key = st.sidebar.text_input('Enter API key:', type='password')
    if api_key:
        st.session_state['api_key'] = api_key
        st.sidebar.success('API key provided!', icon='âœ…')

# Unified function to generate completions from different models.
def generate_completion(prompt, model, messages=None, temperature=0.7, max_tokens=2048, n=1, stop=None):
    endpoint = 'https://api.together.xyz/v1/completions'
    headers = {"Authorization": f"Bearer {st.session_state['api_key']}"}
    json_payload = {
        "model": model,
        "prompt": prompt,
        "messages": messages,
        'temperature': temperature,
        'max_tokens': max_tokens,
        'n': n,
        'stop': stop
    }
    response = requests.post(endpoint, json=json_payload, headers=headers)
    if response.status_code == 200:
        return response.json()
    else:
        st.error(f"Failed to generate summary. API responded with status code: {response.status_code}. Response: {response.text}")
        return None

# Model identifiers mapping.
model_identifiers = {
    "Mistral": "mistralai/Mistral-7B-Instruct-v0.2",
    "Llama": "togethercomputer/Llama-2-7B-32K-Instruct",
    "Qwen": "Qwen/Qwen1.5-1.8B-Chat"
}

# Main interaction area for user input with enhanced processing and display logic.
if 'api_key' in st.session_state:
    USER_PROMPT = st.text_area("Enter your discussion:")
    if USER_PROMPT:
        USER_PROMPT = re.sub(r"^\d+\n|\d+:\d+:\d+,\d+ --> \d+:\d+:\d+,\d+\n|\[.+?\]\n|\n\n+", '', USER_PROMPT)
        USER_PROMPT = re.sub(r'(\d+)(?=\n)', '', USER_PROMPT)
        USER_PROMPT = re.sub(r'\[[^\]]+\]', '', USER_PROMPT)
        USER_PROMPT = re.sub(r'\n+', ' ', USER_PROMPT)

        system_prompt = prompts.get(selected_model, "")
        complete_prompt = f"{system_prompt}\n\n{USER_PROMPT}" if system_prompt else USER_PROMPT

        model_name = model_identifiers.get(selected_model, "")
        response = generate_completion(complete_prompt, model_name, temperature=0.7, max_tokens=2048, n=1)

        if response and "choices" in response and response["choices"]:
            summary = response["choices"][0].get("text", "No summary generated.")
            if summary:
                st.write("### Generated Summary:")
                st.write(summary)
            else:
                st.error("The model was unable to generate a summary. Please try again or modify your input.")
        else:
            st.error("Failed to generate a summary. Please check your API key and model selection, or try again later.")